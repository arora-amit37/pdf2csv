# üìë HECM PDF-to-CSV Extraction Pipeline

Welcome to the **HECM Data Pipeline**! This repository is a professional-grade toolkit designed to tackle the "wild west" of PDF data extraction. Whether you're dealing with blurry scans or inconsistent formatting, this project uses OCR and heavy-duty data post-processing to bring order to the chaos.

---

## üèóÔ∏è The Big Picture

The project is split into two main phases:
1. **Extraction (The Pythons):** Walking through directories of PDFs, turning images into text, and saving the raw data.
2. **Post-Processing (The Notebooks):** Cleaning the "OCR-isms," standardizing names (e.g., fixing `W3LLS FARG0`), and validating financial fields.

---

## üìÇ File Breakdown

### üêç The Extraction Scripts (`process_pdfs_vX.py`)
These scripts are the workhorses that handle the heavy lifting of OCR.

* **`process_pdfs_V1.py`**: The prototype. Uses `pdfplumber` and `pytesseract` to attempt text extraction. It introduces a **checkpointing system** so if your computer crashes at file 999, you don't lose progress.
* **`process_pdfs_V2.py`**: The "Raw Text" Edition. It adds a critical `raw_text` column. This preserves the original OCR string, allowing for more complex regex cleaning later without re-running the hours-long OCR process.
* **`process_pdfs_V3.py`**: The Performance Optimizer. This version adds image enhancement (sharpening and contrast) to improve Tesseract's accuracy and implements more robust multi-processing with live progress tracking (ETA, rate, etc.).

### üìì The Post-Processing Notebooks (`Fair_vX.ipynb`)
This is where the data is refined from "messy text" into "clean insights."

* **`Fair_V1.ipynb`**: The Laboratory. Used for initial data exploration and testing fuzzy matching logic to group inconsistent lender names (e.g., "SUN WEST" vs "SUN WEST MORTGAGE").
* **`Fair_V2.ipynb`**: The Cleaning Factory. Implements massive mapping dictionaries (e.g., `status_map`) to fix OCR errors in categorical fields like `es_status`. It converts strings like `Temurated` back into `Terminated`.
* **`Fair_V3.ipynb`**: The Final Export. Focuses on final data integrity‚Äîformatting dates into standard `YYYY-MM-DD`, validating ages are within human ranges (55-95), and exporting the final "Master" dataset.

---

## üõ†Ô∏è Tech Stack

* **OCR:** [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
* **Engine:** Python 3.x
* **Data Wrangling:** Pandas & NumPy
* **String Matching:** `thefuzz` (FuzzyWuzzy)
* **PDF Processing:** `pdf2image` (Poppler) & `pdfplumber`

---

## üöÄ How to Run

1.  **Configure Paths:** Update the `PDF_DIR` and `tesseract_cmd` paths in the `.py` scripts to match your local environment.
2.  **Extract:** Run `python process_pdfs_V3.py`. Grab a coffee; OCR takes time.
3.  **Clean:** Open `Fair_V3.ipynb` and run all cells to process the `master_output.csv` generated by the script.
4.  **Analyze:** Your clean data will be waiting for you in `export_V3.csv`.

---

## üí° Why This Exists?
Mortgage data is notoriously hard to extract from legacy PDF systems. This pipeline ensures that even if the OCR makes a mistake, the post-processing logic is robust enough to catch and correct it, resulting in a dataset you can actually trust for financial modeling.
